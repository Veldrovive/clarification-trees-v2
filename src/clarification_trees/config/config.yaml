# training:
#   epochs: 5
#   seed: 42
#   device: 'cuda:7'
#   batch_size: 1
#   lr: 2e-4
#   weight_decay: 0.01
#   gradient_accumulation_steps: 10
#   max_grad_norm: 1.0
#   warmup_ratio: 0.03

dialog_tree:
  max_depth: 2
  question_expansion_factor: 2
  answer_expansion_factor: 2
  question_diverse_sample_count: 5  # Questions are generally naturally diverse so 5 samples should produce at least 2 clusters
  answer_diverse_sample_count: 5  # Answers are generally not very diverse, but when there is only one answer there is only one answer.
  # There being multiple answers often indicates that the model is trying to give away the answer.

devices:
  clarification: 'cuda:3'
  answer: 'cuda:4'
  semantic_cluster: 'cuda:4'

defaults:
  # - clarification_model: qwen_3_vl_32b_lora_small
  # - clarification_model: qwen_3_vl_32b_prompt_tune
  # - clarification_model: qwen_3_vl_8b_lora_no_quant
  - clarification_model: qwen_3_vl_32b_lora_bfloat16
  - answer_model: qwen_3_vl_32b
  - semantic_cluster_model: hybrid_clusterer

paths:
  data:
    clearvqa: /scratch4/home/adempst/projects/clarification-trees-v2/data/clearvqa
  checkpoints:
    loras: /scratch4/home/adempst/projects/clarification-trees-v2/checkpoints/loras

runtime_meta:
  git_commit: null
  git_strict: true